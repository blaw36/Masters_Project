---
title: "Intro to genotype wavelets"
author: "Brendan Law"
date: "03/06/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plotly)
library(data.table)
library(reshape2)

data.path = "~/Cpp/WaveQTL/data/dsQTL/"
source("~/Cpp/WaveQTL/R/WaveQTL_preprocess_funcs.R")
```

### Load SNP data

24 SNPs, for 70 individuals. SNPs are single nucleotide polymorphism - a common type of genetic variation among people (must be seen in at least some x% threshold of the population to be a valid SNP). An SNP may be replacing a particular nucleotide of a DNA (C for a T, for example). See [here](https://ghr.nlm.nih.gov/primer/genomicresearch/snp) for some details. Our data is genotype data at genetic variants (mainly SNPs), coded as a number, $g \in \{0,1,2\}$, representing the number of copies of the minor allele (which may be one of the A,T,G,C I think?). An example illustrated in class showed how we may have, for two nucleotides, say AG, the possible combinations: AA, AG, GA, GG, with one of these being coded as a 'minor allele', and hence giving us either 0, 1 or 2 copies of it. Some (standard) imputation is then performed to generate probabilities of each combination, and the final number (a value between 0 and 2) represents the probability-weighted average of the number of copies of the minor allele at the single SNP of interest. [^1]

```{r, echo = FALSE}

eg_geno <- as.matrix(read.table(paste0(data.path,"chr17.10160989.10162012.2kb.cis.geno")))

eg_geno.2 = data.frame(t(eg_geno[,c(4:73)]))
names(eg_geno.2) <- eg_geno[,1]

lapply(eg_geno.2,table)
```

### Read in phenotype data

Counts at 1024 bases, for 70 individuals.

```{r pressure, echo = FALSE}
# read functional phenotypic data
pheno.dat = as.matrix(read.table(paste0(data.path,"chr17.10160989.10162012.pheno.dat")))
pheno.dat.2=data.frame(t(pheno.dat))
pheno.dat.2 = melt(pheno.dat.2)
pheno.dat.2$loc = rep(1:1024,70)

# All in one colour
ggplot(pheno.dat.2) + geom_path(aes(x = loc, y = value, group = factor(variable), alpha = 0.5))

# Summary stats
ggplot(melt(t(apply(pheno.dat,2,summary)))) +
  geom_path(aes(x = as.numeric(Var1), y = value, group = factor(Var2), colour = factor(Var2))) +
  scale_x_continuous(breaks = seq(0,1024,by = 64)) + xlab("Base location") +
  guides(colour = guide_legend("Stat"))

# Means only
mean.pheno = data.frame(mean = apply(pheno.dat,2,mean), loc = 1:1024)
ggplot(mean.pheno) +
  geom_line(aes(x = loc, y = mean)) +
  scale_x_continuous(breaks = seq(0,1024,by = 64)) +
  xlab("Base location")

```

### Combining both
The goal of this project is to:
  - Identify base locations which contain significant effects between individual SNPs and the count data obtained from sequencing
  - Estimate the effect of the SNP value on the sequenced count data at each base

So, this exercise involves taking two SNPs, for example, and trying to plot 70 individuals' worth of counts, and giving different colours depending on their SNP values. A fairly fruitless task given how noisy the data is. 

```{r, echo = FALSE}
# SNP 1:
# chr17.10159002
pheno.and.geno = cbind(pheno.dat)
pheno.and.geno.2 = data.frame(t(pheno.and.geno))
pheno.and.geno.2 = melt(pheno.and.geno.2)
pheno.and.geno.2$loc = rep(1:1024,70)
pheno.and.geno.2$snp = rep(eg_geno.2$chr17.10159002,each = 1024)

ggplot(pheno.and.geno.2) + 
  geom_path(aes(x = loc, y = value, group = factor(snp), colour = snp, alpha = 0.5))
# Not run, as the plotly html widget generated is really large. Try it yourself!
# ggplotly(
#   ggplot(pheno.and.geno.2) + 
#     geom_path(aes(x = loc, y = value, group = factor(snp), colour = snp, alpha = 0.5))
# )
ggplot(pheno.and.geno.2) + 
  geom_path(aes(x = loc, y = value, group = factor(snp), colour = between(as.numeric(as.character(snp)), 0.03, 0.08), alpha = 0.5)) +
  guides(colour = F)

# SNP 2:
# chr17.10161485
pheno.and.gen.more = cbind(pheno.dat)
pheno.and.gen.more.2 = data.frame(t(pheno.and.gen.more))
pheno.and.gen.more.2 = melt(pheno.and.gen.more.2)
pheno.and.gen.more.2$loc = rep(1:1024,70)
pheno.and.gen.more.2$snp = rep(eg_geno.2$chr17.10161485,each = 1024)

# Not run, as the plotly html widget generated is really large. Try it yourself!
# ggplotly(
#   ggplot(pheno.and.gen.more.2) + 
#     geom_path(aes(x = loc, y = value, group = factor(snp), colour = snp, alpha = 0.5))
# )
ggplot(pheno.and.gen.more.2) + 
  geom_path(aes(x = loc, y = value, group = factor(snp), colour = between(as.numeric(as.character(snp)), 0.9, 1), alpha = 0.5)) +
  guides(colour = F)
```

Another way we can represent this is to, for example, bin our observations into the SNP they are closest to (based on the SNP data we've been given), and give an average count 'function'. In a way, we're reproducing a kind of figure seen on page 14 of the Shim and Stephens (2014) paper. That probably uses slightly adjusted count data (normalised for total read length at each base, covariates regressed out, etc, which we won't do here). Take the significant, chr17.10161485, for example
```{r}
library(tidyverse)
# Bin the individuals up
# SNP 2:
# chr17.10161485
pheno.and.gen.bin = cbind(pheno.dat,snp = as.numeric(as.character(eg_geno.2$chr17.10161485)))
pheno.and.gen.bin = data.frame(pheno.and.gen.bin)
pheno.and.gen.bin$bin = round(pheno.and.gen.bin$snp)
pheno.and.gen.bin.averaged = pheno.and.gen.bin %>% 
  group_by(bin) %>%
  summarise_all(funs(mean)) %>%
  select(-"snp")
pheno.and.gen.bin.averaged = melt(pheno.and.gen.bin.averaged, id.vars = 'bin')
pheno.and.gen.bin.averaged$loc = rep(1:1024, each = 3)

ggplot(pheno.and.gen.bin.averaged) + 
  geom_path(aes(x = loc, y = value, group = factor(bin), colour = factor(bin))) +
  labs(colour = "Imputed SNP")
```

A short guide to wavelet analysis on the sequenced count data. Let's try and look at two individuals whose counts data are very different: one displays a lot of variation, the other does not: (note this is the raw wavelet count, NOT pre-processed to filter out low count WCs, or normalised against read counts, just to give a flavour of what wavelets on this data looks like).
```{r, echo = FALSE}
order(apply(pheno.dat, MARGIN = 1, var))
```
Individuals 21 (little variation) and 69 (a lot of variation)

```{r, echo = FALSE}
two_datasets <- pheno.dat[c(21,69),]

wlet_21 <- wd(two_datasets[1,], filter.number = 1, family = "DaubExPhase")
wlet_69 <- wd(two_datasets[2,], filter.number = 1, family = "DaubExPhase")

# Plot 21 vs 69
two_datasets_plot = data.frame(t(two_datasets))
two_datasets_plot = melt(two_datasets_plot)
two_datasets_plot$variable = rep(c(21,69), each = 1024)
two_datasets_plot$loc = rep(1:1024, 2)
ggplot(two_datasets_plot) +
  geom_path(aes(x = loc, y = value, group = factor(variable), colour = factor(variable)))

# Plot 21, and its w/let decomp
plot(two_datasets_plot[two_datasets_plot$variable == 21, "loc"]
     ,two_datasets_plot[two_datasets_plot$variable == 21, "value"]
     ,xlab = "base", ylab = "count", type = "l"
     ,ylim = c(0,3))
plot(wlet_21, scaling = "by.level", main = "")

# Plot 69, and its w/let decomp
plot(two_datasets_plot[two_datasets_plot$variable == 69, "loc"]
     ,two_datasets_plot[two_datasets_plot$variable == 69, "value"]
     ,xlab = "base", ylab = "count", type = "l"
     ,ylim = c(0,3))
plot(wlet_69, scaling = "by.level", main = "")
```

A more relevant exercise would be to take the difference of these two individuals, and then transform that into a wavelet space. Our exercise here is an attempt to model differences in the wavelet space, and then transform the differences back into the data space (in the form of beta coefficients - data space differences), so that the wavelet space (combined with certain choices of priors) can denoise some of the differences between the noisy signals. Let's see what that looks like:
```{r differences, echo = F}
differenced_dataset <- two_datasets[1,] - two_datasets[2,]

wlet_diff <- wd(differenced_dataset, filter.number = 1, family = "DaubExPhase")

# Plot 21 vs 69
wlet_diff_plot = data.frame(t(differenced_dataset))
wlet_diff_plot = melt(wlet_diff_plot)
wlet_diff_plot$loc = 1:1024

# Plot diff, and its w/let decomp
plot(wlet_diff_plot[,c("loc","value")]
     ,xlab = "base", ylab = "count", type = "l")
plot(wlet_diff, scaling = "by.level", main = "")
```

<!-- References -->
[^1]: See the Shim and Stephens (2014) paper for some more detail of the input data.
