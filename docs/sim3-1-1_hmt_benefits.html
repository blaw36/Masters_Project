<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Brendan Law" />


<title>sim3_hmt_benefits - v1.1</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Brendan's Masters Project</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/blaw36/Masters_Project">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">sim3_hmt_benefits - v1.1</h1>
<h4 class="author"><em>Brendan Law</em></h4>
<h4 class="date"><em>15/08/2019</em></h4>

</div>


<p>This is v1.1 – builds on ‘sim3_hmt_benefits.Rmd’. Planned refinements: - Better cater for effet sizes - Potentially use simplified effect sizes (flat, large magnitudes, magnitude scaling)</p>
<div id="waveqtl_hmt-vs-waveqtl" class="section level2">
<h2>WaveQTL_HMT vs WaveQTL</h2>
<p>The idea is that the benefits will come from being able to detect signals which are not necessarily strong, and not necessarily broad, but relatively localised. These sorts of signals won’t be captured by WaveQTL as they may be ‘split’ or ‘spread’ across a particular scale, and not propagate strongly enough to lower scales. (???)</p>
<p>Perhaps see Shim and Stephens figures for some examples. Perhaps some of that matter around the middle of Figure 4 may be able to be better captured using a HMT prior. There is potentially some difference between groups here, but very narrow, inconsistent, and seemingly very spiky signal.</p>
<div id="read-in-phenotype-sequencing-count-data-and-other-auxillary-data" class="section level3">
<h3>Read in phenotype (sequencing count) data, and other auxillary data</h3>
<p>Here is just a sample codebase. We’re working off the data in the WaveQTL git repo – DNase-seq data at chr17.10160989.10162012 and genotypes at 24 SNPs in 2kb cis-candidate region on 70 individuals.</p>
<pre class="r"><code>pheno.dat = as.matrix(read.table(paste0(input_data_path, &quot;chr17.10160989.10162012.pheno.dat&quot;)))
dim(pheno.dat)</code></pre>
<pre><code>## [1]   70 1024</code></pre>
<pre class="r"><code>#[1]   70 1024

### Is this useful at all? For later on
## read library read depth
library.read.depth = scan(paste0(input_data_path, &quot;library.read.depth.dat&quot;))
length(library.read.depth)</code></pre>
<pre><code>## [1] 70</code></pre>
<pre class="r"><code>## read Covariates
Covariates = as.matrix(read.table(paste0(input_data_path, &quot;PC4.dat&quot;)))

## Read DWT matrix 
Wmat_1024 = read.table(&quot;~/Cpp/WaveQTL/data/DWT/Wmat_1024&quot;,as.is = TRUE)
W2mat_1024 = Wmat_1024*Wmat_1024

# ## Read in SNPs
# geno_data = read.table(&quot;~/Cpp/WaveQTL/data/dsQTL/chr17.10160989.10162012.2kb.cis.geno&quot;,as.is = TRUE)
# geno_data = geno_data[11,4:73]
#
# # Group based on midpoint of the data
# med_data &lt;- median(as.numeric(as.vector(geno_data[1,])))
# group_data &lt;- as.numeric(as.numeric(as.vector(geno_data[1,])) &gt;= med_data)
# write.table(t(c(&quot;blah&quot;,&quot;A&quot;,&quot;A&quot;,group_data)), file= paste0(&quot;~/Cpp/WaveQTL_HMT/data/dsQTL/&quot;, &quot;sim3.cis.geno&quot;), row.names=FALSE, col.names = FALSE, quote=FALSE)

# Generate own SNPs data
group_data &lt;- rbinom(n = 70,size = 1,prob = 0.5)
write.table(t(c(&quot;blah&quot;,&quot;A&quot;,&quot;A&quot;,group_data)), file= paste0(&quot;~/Cpp/WaveQTL_HMT/data/dsQTL/&quot;, &quot;sim3.cis.geno&quot;), row.names=FALSE, col.names = FALSE, quote=FALSE)</code></pre>
<p>Now, summarise the counts, and average:</p>
<pre class="r"><code># Count summation
seq_sum &lt;- apply(pheno.dat,MARGIN = 2,sum)
# Count average
seq_avg &lt;- apply(pheno.dat,MARGIN = 2,mean)
plot(seq_sum, type = &quot;l&quot;)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>plot(seq_avg, type = &quot;l&quot;)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-2-2.png" width="672" /> These are very small counts over 70 individuals (like 0 - 25).</p>
</div>
<div id="simulate-effect-sizes-and-effect-locations." class="section level3">
<h3>Simulate effect sizes and effect locations.</h3>
<p>What we now need is, for each base, <span class="math inline">\(b = 1,\dots,1024\)</span>, the estimated (data-space) effect size, as well as the locations where there are effects. A lot of this work was done in ‘sim1_waveqtl_hmt_gamma_phi.Rmd’. So what i’ll do (for now) is just drop the code in to get an example output for the 11th SNP/genotype, as was done in that markdown.</p>
<p>The following extracts effect sizes (in the data space) for this DNase-seq data vs SNP 11, using WaveQTL_HMT.</p>
<pre class="r"><code>waveqtl_hmt_geno11 &lt;- with_hmt_effect_size(data_path = data_path
                                           ,dataset = dataset
                                           ,waveqtl_dataset = paste0(&quot;WaveQTL/&quot;,waveqtl_dataset)
                                           ,Wmat_1024 = Wmat_1024
                                           ,geno_select = 11
                                           ,plot_title = &quot;Posterior mean +/3 posterior standard deviaion - SNP 11&quot;)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Looks about right. Most importantly, we have mean effect sizes, and the locations where we have effects:</p>
<pre class="r"><code># Base-level effect sizes:
length(waveqtl_hmt_geno11$beta_dataS)</code></pre>
<pre><code>## [1] 1024</code></pre>
<pre class="r"><code># Locations of effects:
length(waveqtl_hmt_geno11$col_posi)</code></pre>
<pre><code>## [1] 144</code></pre>
</div>
<div id="simulate-realistic-effect-lengths" class="section level3">
<h3>Simulate realistic effect lengths</h3>
<p>For example, let’s do effect length 5, 10, and 50.</p>
<p>I’ve created some functions which either:</p>
<ul>
<li>Picks an effect interval which lies within the above effect areas</li>
<li>If the length of interval we require is longer than any above effect area, pick the longest effect area possible for our interval</li>
</ul>
<pre class="r"><code># Generate table summary of data-space effect areas
int_table &lt;- summarise_effect_intervals(waveqtl_hmt_geno11$col_posi)

set.seed(10)
effect_5 &lt;- effect_length_picker(int_table,5)
effect_10 &lt;- effect_length_picker(int_table,10)
effect_50 &lt;- effect_length_picker(int_table,50)

length(effect_5)</code></pre>
<pre><code>## [1] 5</code></pre>
<pre class="r"><code>length(effect_10)</code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="r"><code>length(effect_50)</code></pre>
<pre><code>## [1] 50</code></pre>
</div>
<div id="simulate-realistic-effect-size" class="section level3">
<h3>Simulate realistic effect size</h3>
<p>Generate effect sizes, and corresponding probabilities. Method is as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Convert the mean effect into a proportion of baseline vs with effect (note that the effect can go both ways). Baseline is a group with no effect, as opposed to the other group, which has an effect at given base. We convert an additive effect (as per modelling assumptions) into a multiplicative ratio by: <span class="math display">\[\begin{align}
  c_t \frac{1}{70} + \alpha &amp;= \frac{1}{70} c_t e_t \\
  \therefore e_t &amp;= 1 + \frac{70 \alpha}{c_t}
\end{align}\]</span> where <span class="math inline">\(c_t\)</span> is the total sum of counts at each base, and <span class="math inline">\(e_t\)</span> is the new (ratio’d) effect size. Hence, we’re trying to convert something of arbitrary size to something in <span class="math inline">\((0,\infty)\)</span>, where 1 means 0 effect.</p></li>
<li><p>We then convert these effect sizes into a <span class="math inline">\(p\)</span> parameter for our beta-binomial sampling. The original idea is to draw, at each base, a number of trials = total sum of counts (from all 70 individuals), with a probability of success around 1/70, so that the mean number of counts at any base should correspond to the sample average number of counts at any base. We need to augment this to have two parameters, <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span>, where <span class="math inline">\(p_2\)</span> reflects the effect size. In order to do this, we assume we draw two sets of data, with total proportion <span class="math inline">\(p_1 + p_2 = \frac{2}{70}\)</span>, and alter the effect sizes according to: <span class="math display">\[\begin{align}
  p_{1,b} &amp;= \frac{2}{70} \frac{1}{1 + e_b} \\
  p_{2,b} &amp;= \frac{2}{70} \frac{e_b}{1 + e_b} \\
\end{align}\]</span> where <span class="math inline">\(p_{1,b}, p_{2,b}\)</span> are the proportions, at base <span class="math inline">\(b\)</span> when there is no effect, and where there is effect, respectively. Note in the final plot, how they are similar where no effect has been observed, but diverge (yet still together sum to $) when there is an effect.</p></li>
</ol>
<p>We note that due to the small effect size, the divergence, despite looking large in the plot, is REALLY small in practice. We may need to scale this up and down a little to find the ‘sweet spot’ usefulness of our algo.</p>
<p><strong>Notes</strong>:</p>
<ul>
<li>Where no count at a given base, <span class="math inline">\(c_t\)</span>, assume <span class="math inline">\(e_t = 1\)</span> (ie. no effect). Doesn’t make a difference anyway, as, for these bases, we will simulate drawing from 0 sequencing counts, resulting in a 0 simulated total count. Hence, effect or not, the number of counts here will always be 0.</li>
<li>We will assume that the effect size ratio = 1 everywhere, outside the required effect window (in a later step)</li>
<li>For the null dataset, all groups will be drawn from the same distribution (probability = 1/70) – see page 170 of the workings of previous work</li>
</ul>
<p>Here is a methodology sample, without incorporating effect size:</p>
<pre class="r"><code>plot(waveqtl_hmt_geno11$beta_dataS, type = &quot;l&quot;, main = &quot;waveQTL effect size in data space&quot;)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code># Convert effect into ratio
effect_ratio &lt;- 1 + (70*waveqtl_hmt_geno11$beta_dataS/seq_sum)
effect_ratio[seq_sum == 0] &lt;- 1
plot(effect_ratio, type = &quot;l&quot;, main= &quot;effect size converted to effect ratio (alt/null)&quot;)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<pre class="r"><code># Incorporate ratio into proportion parameter
p1_vector &lt;- 2/70 * (1/(1 + effect_ratio))
p2_vector &lt;- 2/70 * (effect_ratio/(1 + effect_ratio))

# Plot raw p1,p2
par(mar = c(2,4,4,2))
plot(1,1,type=&quot;n&quot;
     , xlab = &quot;Base location&quot;
     , ylab = &quot;p parameter&quot;
     , ylim=c(min(min(p1_vector),min(p2_vector)), max(max(p1_vector),max(p2_vector)))
     , xlim=c(1, 1024)
     , main =&quot;Simulation - p1 (no effect) vs p2 (effect) parameters - before effect window&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
abline(h = 0, col = &quot;red&quot;)
lines(p1_vector, col = &quot;blue&quot;)
lines(p2_vector, col = &quot;black&quot;)
legend(&quot;topleft&quot;, legend=c(&quot;p1&quot;, &quot;p2&quot;),
       col=c(&quot;blue&quot;, &quot;black&quot;), lty=c(1,1), cex=0.8,
       box.lty=0)
box()</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-6-3.png" width="672" /></p>
<pre class="r"><code>p &lt;- recordPlot()

## Now plot the means (multiply by sequencing sums)
par(mar = c(2,4,4,2))
plot(1,1,type=&quot;n&quot;
     , xlab = &quot;Base location&quot;
     , ylab = &quot;p parameter&quot;
     , ylim=c(min(min(p1_vector*seq_sum),min(p2_vector*seq_sum))
              , max(max(p1_vector*seq_sum),max(p2_vector*seq_sum)))
     , xlim=c(1, 1024)
     , main =&quot;Simulation - mean g1 (no effect) vs mean g2 (effect) parameters - before effect window&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
abline(h = 0, col = &quot;red&quot;)
lines(p1_vector*seq_sum, col = &quot;blue&quot;)
lines(p2_vector*seq_sum, col = &quot;black&quot;)
legend(&quot;topleft&quot;, legend=c(&quot;p1&quot;, &quot;p2&quot;),
       col=c(&quot;blue&quot;, &quot;black&quot;), lty=c(1,1), cex=0.8,
       box.lty=0)
box()</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-6-4.png" width="672" /></p>
<pre class="r"><code>p &lt;- recordPlot()

## Now plot the difference in means (multiply by sequencing sums)
par(mar = c(2,4,4,2))
plot(1,1,type=&quot;n&quot;
     , xlab = &quot;Base location&quot;
     , ylab = &quot;p parameter&quot;
     , ylim=c(min(min((p1_vector - p2_vector)*seq_sum),min((p1_vector - p2_vector)*seq_sum))
              , max(max((p1_vector - p2_vector)*seq_sum),max((p1_vector - p2_vector)*seq_sum)))
     , xlim=c(1, 1024)
     , main =&quot;Simulation - mean g1 (no effect) vs mean g2 (effect) parameters - before effect window&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
abline(h = 0, col = &quot;red&quot;)
lines((p1_vector - p2_vector)*seq_sum, col = &quot;blue&quot;)
lines((p1_vector - p2_vector)*seq_sum, col = &quot;black&quot;)
legend(&quot;topleft&quot;, legend=c(&quot;p1&quot;, &quot;p2&quot;),
       col=c(&quot;blue&quot;, &quot;black&quot;), lty=c(1,1), cex=0.8,
       box.lty=0)
box()</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-6-5.png" width="672" /></p>
<pre class="r"><code>p &lt;- recordPlot()</code></pre>
<p>Can see that the really, really small difference in effect size resuls in very little difference between the mean counts at any base.</p>
<p>Here is the same thing, now only generating an effect in the designated 50-length effect window:</p>
<pre class="r"><code># Incorporate ratio into proportion parameter
# Initialise as 1/70 everywhere for both
p1_vector &lt;- rep(1/70,1024)
p2_vector &lt;- rep(1/70,1024)

# Add in effects, where required
p1_vector[effect_50] &lt;- 2/70 * (1/(1 + effect_ratio[effect_50]))
p2_vector[effect_50] &lt;- 2/70 * (effect_ratio[effect_50]/(1 + effect_ratio[effect_50]))

y_min &lt;- min(min(p1_vector),min(p2_vector))
y_max &lt;- max(max(p1_vector),max(p2_vector))
par(mar = c(2,4,4,2))
plot(1,1,type=&quot;n&quot;
     , xlab = &quot;Base location&quot;
     , ylab = &quot;p parameter&quot;
     , ylim=c(y_min, y_max)
     , xlim=c(1, 1024)
     , main =&quot;Simulation - p1 (null) vs p2 (alt) parameters - after effect window&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
abline(h = 0, col = &quot;red&quot;)
if(length(effect_50) &gt; 0){
  for(j in 1:length(effect_50)){
    polygon(c(effect_50[j]-0.5, effect_50[j]-0.5, effect_50[j]+0.5, effect_50[j]+0.5), c(y_min-2, y_max+2, y_max+2, y_min-2), col =&quot;pink&quot;, border = NA)
  }
}
lines(p1_vector, col = &quot;blue&quot;)
lines(p2_vector, col = &quot;black&quot;)
legend(&quot;topleft&quot;, legend=c(&quot;p1&quot;, &quot;p2&quot;),
       col=c(&quot;blue&quot;, &quot;black&quot;), lty=c(1,1), cex=0.8,
       box.lty=0)
box()</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>p &lt;- recordPlot()</code></pre>
</div>
<div id="combine-the-two-to-create-simulations" class="section level3">
<h3>Combine the two to create simulations</h3>
<p>Have a 1024 length vector where we know:</p>
<ul>
<li>Which bases we want an effect for (everywhere else, effect = 1)</li>
<li>The total sequence counts (# of trials) at each base</li>
<li>The probability parameter which governs the sequencing count at each base, to mimic the ‘effect size’</li>
</ul>
<p>Then, we need to process the data, run it through WaveQTL and WaveQTL_HMT, and analyse the results – ie replicate the effect size plots. Along the way, we should also visualise the null and alternative datasets we’ve generated.</p>
<p>Just a note about the ‘rmutil::rbetabinom’ function – the parameterisation is different.</p>
<p>Sometimes, we denote: <span class="math display">\[\begin{align*}
X &amp;\sim Beta-Binomial(n,\alpha,\beta) \\
\Rightarrow P(X = k) &amp;= \binom{n}{k}\frac{B(k + \alpha, n - k + \beta)}{B(\alpha, \beta)}
\end{align*}\]</span> where <span class="math inline">\(B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\)</span> is the beta function. An alternative parameterisation, as per rbetabinom, is to use two parameters, <span class="math inline">\(m\)</span>, a probability (corresponding to the <span class="math inline">\(p = \frac{\alpha}{\alpha + \beta}\)</span> of the original), and <span class="math inline">\(s\)</span>, an overdispersion parameter. In this representation, we have: <span class="math display">\[\begin{align*}
X &amp;\sim Beta-Binomial(n,m,s) \\
\Rightarrow P(X = k) &amp;= \binom{n}{k}\frac{B(k + sm, n - k + s(1-m))}{B(sm, s(1-m))}
\end{align*}\]</span> This corresponds to: <span class="math display">\[\begin{align*}
\alpha &amp;= sm \\
\beta &amp;= s(1-m) \\
\therefore m &amp;= \frac{\alpha}{\alpha + \beta} \\
\therefore s &amp;= \alpha + \beta
\end{align*}\]</span></p>
<p>We need to generate null and alternative samples. We want to create 70 x 1024 matrices – 70 individuals, 1024 bases. We fill out each column of our matrix by taking 70 samples from a beta-binomial to populate each column. Our beta binomial does the ‘total count at base b’ number of trials, but the parameters have the ‘divide by 70’ inbuilt, so the proportion of any one individual having a count is very low. The mean count for each column corresponds to around sum of counts divide by 70, which is the desired mean (sample mean of counts).</p>
<p>Set up beta-binomial distribution, with regards to effect area</p>
<pre class="r"><code>over_disp_mult &lt;- 1/70
p1_alpha &lt;- over_disp_mult*p1_vector
p1_beta &lt;- over_disp_mult - p1_alpha
p2_alpha &lt;- over_disp_mult*p2_vector
p2_beta &lt;- over_disp_mult - p2_alpha

# Check to see that these alphas and betas generate the desired probabilities
all.equal(p1_vector, p1_alpha/(p1_alpha + p1_beta))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>all.equal(p2_vector, p2_alpha/(p2_alpha + p2_beta))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Length 50 sample – generate both null and alt. Based on the genotype groups (0 or 1), for the alt, we draw either p1 or p2. For the null dataset, we draw 1/70 for both (no effect). Note that sequencing sum counts aren’t always whole numbers. to deal with this, we draw a ceiling(sum) number of trials.</p>
<pre class="r"><code>set.seed(6)
# # Null
# null_data_50 &lt;- matrix(nrow = 70,ncol = 1024)
# for(i in 1:1024){
#   null_data_50[,i] &lt;- rmutil::rbetabinom(n = 70, size = ceiling(as.numeric(as.vector(seq_sum[i])))
#                                          , m = (p1_alpha/(p1_alpha+p1_beta))[i]
#                                          , s = (p1_alpha+p1_beta)[i])
# }
# 
# # Alt
# alt_data_50 &lt;- matrix(nrow = 70,ncol = 1024)
# for(i in 1:1024){
#   alt_data_50[,i] &lt;- rmutil::rbetabinom(n = 70, size = ceiling(as.numeric(as.vector(seq_sum[i])))
#                                         , m = (p2_alpha/(p2_alpha+p2_beta))[i]
#                                         , s = (p2_alpha+p2_beta)[i])
# }

# Null
null_data_50 &lt;- matrix(nrow = 70,ncol = 1024)
for(j in 1:1024){
  null_data_50[,j] &lt;- rmutil::rbetabinom(n = 70, size = as.numeric(as.vector(ceiling(seq_sum[j])))
                                         , m = 1/70
                                         , s = over_disp_mult)  
}

# Alt
# For alt dataset, create a 70 X 1024 matrix, based on group membership, assigning p1 or p2, respectively
param_mtx &lt;- matrix(nrow = 70,ncol = 1024)
n &lt;- 1
for(i in group_data){
  if(i == 1){
    param_mtx[n,] &lt;- (p2_alpha/(p2_alpha+p2_beta))
  }else{
    param_mtx[n,] &lt;- (p1_alpha/(p1_alpha+p1_beta))
  }
  n &lt;- n + 1
}

alt_data_50 &lt;- matrix(nrow = 70,ncol = 1024)
for(j in 1:1024){
  for(i in 1:70){
    alt_data_50[i,j] &lt;- rmutil::rbetabinom(n = 1, size = as.numeric(as.vector(ceiling(seq_sum[j])))
                                         , m = param_mtx[i,j]
                                         , s = over_disp_mult)  
  }
}</code></pre>
<p>Plot the average of the two together?</p>
<pre class="r"><code>null_data_50_avg &lt;- apply(null_data_50,2,sum)
alt_data_50_avg &lt;- apply(alt_data_50,2,sum)

plt_rng_y &lt;- c(min(min(null_data_50_avg),min(alt_data_50_avg)) * 0.5, max(max(null_data_50_avg),max(alt_data_50_avg)) * 1.5)

par(mfrow = c(4,1),mar = c(2,4,4,1))
plot(1,1,type=&quot;n&quot;
     , xlab = &quot;position&quot;
     , ylab = &quot;count&quot;
     , ylim=plt_rng_y
     , xlim=c(1, 1024)
     , main =&quot;Simulation - null vs alt datasets - effect of length 50&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
if(length(effect_50) &gt; 0){
  for(j in 1:length(effect_50)){
    polygon(c(effect_50[j]-0.5, effect_50[j]-0.5, effect_50[j]+0.5, effect_50[j]+0.5), c(plt_rng_y[1], plt_rng_y[2], plt_rng_y[1], plt_rng_y[2]), col =&quot;pink&quot;, border = NA)
  }
}
lines(null_data_50_avg, col = &quot;blue&quot;, lty = &quot;dashed&quot;)
lines(alt_data_50_avg, col = &quot;red&quot;, lty = &quot;dashed&quot;)
box()

plot(1,1,type=&quot;n&quot;
     , xlab = &quot;position&quot;
     , ylab = &quot;count&quot;
     , ylim=plt_rng_y
     , xlim=c(1, 1024)
     , main =&quot;Simulation - null dataset - effect of length 50&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
lines(null_data_50_avg, col = &quot;blue&quot;, lty = &quot;dashed&quot;)
box()

plot(1,1,type=&quot;n&quot;
     , xlab = &quot;position&quot;
     , ylab = &quot;count&quot;
     , ylim=plt_rng_y
     , xlim=c(1, 1024)
     , main =&quot;Simulation - alt dataset - effect of length 50&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
if(length(effect_50) &gt; 0){
  for(j in 1:length(effect_50)){
    polygon(c(effect_50[j]-0.5, effect_50[j]-0.5, effect_50[j]+0.5, effect_50[j]+0.5), c(plt_rng_y[1], plt_rng_y[2], plt_rng_y[1], plt_rng_y[2]), col =&quot;pink&quot;, border = NA)
  }
}
lines(alt_data_50_avg, col = &quot;red&quot;, lty = &quot;dashed&quot;)
box()

plt_rng_y_2 &lt;- c(min(alt_data_50_avg - null_data_50_avg) * 0.9999999999999, max(alt_data_50_avg - null_data_50_avg) * 1.000000000000001)
plot(1,1,type=&quot;n&quot;
     , xlab = &quot;position&quot;
     , ylab = &quot;count&quot;
     , ylim=plt_rng_y_2
     , xlim=c(1, 1024)
     , main =&quot;Simulation - difference - effect of length 50&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
if(length(effect_50) &gt; 0){
  for(j in 1:length(effect_50)){
    polygon(c(effect_50[j]-0.5, effect_50[j]-0.5, effect_50[j]+0.5, effect_50[j]+0.5), c(plt_rng_y_2[1], plt_rng_y_2[2], plt_rng_y_2[1], plt_rng_y_2[2]), col =&quot;pink&quot;, border = NA)
  }
}
lines(alt_data_50_avg - null_data_50_avg, col = &quot;black&quot;)
box()</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>## Now plot the difference in means of simulated counts (multiply by sequencing sums)
g0_mean &lt;- apply(alt_data_50[which(group_data == 0),],2,mean)
g1_mean &lt;- apply(alt_data_50[which(group_data == 1),],2,mean)
plot(1,1,type=&quot;n&quot;
     , xlab = &quot;Base location&quot;
     , ylab = &quot;simulated avg counts&quot;
     , ylim=c(min(min(g0_mean),min(g1_mean))
              , max(max(g0_mean),max(g1_mean)))
     , xlim=c(1, 1024)
     , main =&quot;Simulated data - average of g0 (no effect) vs g1 (effect)&quot;
     , axes=FALSE)
axis(2)
axis(1, at = c(1,seq(128,1024,128)))
abline(h = 0, col = &quot;red&quot;)
lines(g0_mean, col = &quot;red&quot;)
lines(g1_mean, col = &quot;green&quot;)
legend(&quot;topleft&quot;, legend=c(&quot;p1&quot;, &quot;p2&quot;),
       col=c(&quot;red&quot;, &quot;green&quot;), lty=c(1,1), cex=0.8,
       box.lty=0)
box()</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>p &lt;- recordPlot()</code></pre>
</div>
<div id="run-a-sample-analyses" class="section level3">
<h3>Run a sample analyses</h3>
<ul>
<li>Clean both Null and Alt data through WC transform R thingy
<ul>
<li>Do we do all the usual bells and whistles (PCA regression, quantile transforms?)</li>
<li>What tying level?</li>
<li>Same set of covariates, right?</li>
</ul></li>
<li>Null data through WaveQTL and WaveQTL_HMT</li>
<li>Alt data through WaveQTL and WaveQTL_HMT</li>
</ul>
<p>Cleaning the Null dataset:</p>
<pre class="r"><code>wavelet_cleaning_wrapper_function(pheno.dat = null_data_50
                                  ,output.path = &quot;~/Cpp/WaveQTL_HMT/test/dsQTL/sims/length_50/null_data/&quot;
                                  ,library.read.depth = library.read.depth
                                  ,Covariates = Covariates)</code></pre>
<pre><code>## Loading required package: wavethresh</code></pre>
<pre><code>## Warning: package &#39;wavethresh&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## Warning: package &#39;MASS&#39; was built under R version 3.5.3</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre><code>## WaveThresh: R wavelet software, release 4.6.8, installed</code></pre>
<pre><code>## Copyright Guy Nason and others 1993-2016</code></pre>
<pre><code>## Note: nlevels has been renamed to nlevelsWT</code></pre>
<pre><code>## 
## Attaching package: &#39;wavethresh&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:rmutil&#39;:
## 
##     wr</code></pre>
<p>Cleaning the Alt dataset:</p>
<pre class="r"><code>wavelet_cleaning_wrapper_function(pheno.dat = alt_data_50
                                  ,output.path = &quot;~/Cpp/WaveQTL_HMT/test/dsQTL/sims/length_50/alt_data/&quot;
                                  ,library.read.depth = library.read.depth
                                  ,Covariates = Covariates)</code></pre>
<p><em>SHOULD WE ONLY NEED THE NON-QT version for effect sizes? The QT version is for likelihood/association testing - is this something we’re going to be interested in also? Or just ability to identify effects at certain locations?</em></p>
<div id="run-null-dataset" class="section level4">
<h4>Run null dataset</h4>
<p>Run through WaveQTL:</p>
<p>Run through WaveQTL_HMT:</p>
</div>
<div id="run-alt-dataset" class="section level4">
<h4>Run alt dataset</h4>
<p>Run through WaveQTL:</p>
<p>Run through WaveQTL_HMT:</p>
</div>
</div>
<div id="analysis---no-hmt" class="section level3">
<h3>Analysis - no HMT</h3>
<p>Quick effect size analysis and plotting. No_HMT is easy. Read in some more pre-requisite data (like the inverse wavelet transform):</p>
<pre class="r"><code>##### Null
null_50_data_path = &quot;~/Cpp/WaveQTL_HMT/test/dsQTL/output/&quot;
null_50_data_prefix = &quot;sim3_noQT_null&quot;
null_50 &lt;- no_hmt_effect_size(data_path = null_50_data_path
                              ,data_prefix = null_50_data_prefix
                              ,Wmat_1024 = Wmat_1024
                              ,W2mat_1024 = W2mat_1024
                              ,sel_geno_IX = 1)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre class="r"><code>##### Alt
alt_50_data_path = &quot;~/Cpp/WaveQTL_HMT/test/dsQTL/output/&quot;
alt_50_data_prefix = &quot;sim3_noQT_alt&quot;
alt_50 &lt;- no_hmt_effect_size(data_path = alt_50_data_path
                             ,data_prefix = alt_50_data_prefix
                             ,Wmat_1024 = Wmat_1024
                             ,W2mat_1024 = W2mat_1024
                             ,sel_geno_IX = 1)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-18-2.png" width="672" /></p>
</div>
<div id="analysis---with-hmt" class="section level3">
<h3>Analysis - with HMT</h3>
<pre class="r"><code>##### Null
null_50_data_path = &quot;~/Cpp/WaveQTL_HMT/test/dsQTL/output/&quot;
null_50_data_prefix = &quot;sim3_noQT_null&quot;
null_50_hmt &lt;- with_hmt_effect_size(data_path = null_50_data_path
                                    ,dataset = paste0(null_50_data_prefix,&quot;_HMT&quot;)
                                    ,waveqtl_dataset = null_50_data_prefix
                                    ,Wmat_1024 = Wmat_1024
                                    ,geno_select = 1)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre class="r"><code>##### Alt
alt_50_data_path = &quot;~/Cpp/WaveQTL_HMT/test/dsQTL/output/&quot;
alt_50_data_prefix = &quot;sim3_noQT_alt&quot;
alt_50_hmt &lt;- with_hmt_effect_size(data_path = alt_50_data_path
                                   ,dataset = paste0(alt_50_data_prefix,&quot;_HMT&quot;)
                                   ,waveqtl_dataset = alt_50_data_prefix
                                   ,Wmat_1024 = Wmat_1024
                                   ,geno_select = 1)</code></pre>
<p><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-19-2.png" width="672" /></p>
</div>
<div id="ad-hoc-plots" class="section level3">
<h3>Ad hoc plots</h3>
<p>Two final comparisons, by plot:</p>
<p>Null case: <img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-20-1.png" width="672" /><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-20-2.png" width="672" /><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-20-3.png" width="672" /><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-20-4.png" width="672" /></p>
<p>Alt case: <img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-21-1.png" width="672" /><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-21-2.png" width="672" /><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-21-3.png" width="672" /><img src="sim3-1-1_hmt_benefits_files/figure-html/unnamed-chunk-21-4.png" width="672" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
